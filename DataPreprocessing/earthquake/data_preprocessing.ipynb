{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-30T12:31:03.230931Z",
     "start_time": "2025-10-30T12:31:03.222289Z"
    }
   },
   "source": [
    "# 캐글 데이터의 전처리 코드\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 원본 데이터 불러오기\n",
    "try:\n",
    "    df = pd.read_csv(\"원본 데이터/earthquake_data_tsunami.csv\")\n",
    "\n",
    "    # 2. 제외할 컬럼 목록 정의\n",
    "    columns_to_drop = ['sig', 'cdi', 'mmi']\n",
    "\n",
    "    # 3. 해당 컬럼들을 제외한 새 DataFrame 생성\n",
    "    df_preprocessed = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # 4. 전처리된 데이터를 새 파일로 저장\n",
    "    output_filename = \"1차 전처리-필요없는 데이터 제거/train_data.csv\"\n",
    "    df_preprocessed.to_csv(output_filename, index=False)\n",
    "\n",
    "    print(f\"전처리 완료. {output_filename} 으로 저장되었습니다.\")\n",
    "    print(\"남은 컬럼:\", df_preprocessed.columns.to_list())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 'earthquake_data_tsunami.csv' 파일을 찾을 수 없습니다.\")\n",
    "except KeyError as e:\n",
    "    print(f\"오류: {e.args[0]} 컬럼이 원본 파일에 없습니다.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 완료. train_data.csv 으로 저장되었습니다.\n",
      "남은 컬럼: ['magnitude', 'nst', 'dmin', 'gap', 'depth', 'latitude', 'longitude', 'Year', 'Month', 'tsunami']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T12:37:34.244335Z",
     "start_time": "2025-10-30T12:37:34.225171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# USGS데이터 전처리 코드\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # 0. 'query.csv' 파일 불러오기\n",
    "    df = pd.read_csv(\"원본 데이터/query.csv\")\n",
    "\n",
    "    # 1. 'time' 컬럼에서 'Year'와 'Month' 추출\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df['Year'] = df['time'].dt.year\n",
    "    df['Month'] = df['time'].dt.month\n",
    "\n",
    "    # 2. 'mag' 컬럼명을 'magnitude'로 변경\n",
    "    df.rename(columns={'mag': 'magnitude'}, inplace=True)\n",
    "\n",
    "    # 3. 유지할 최종 컬럼 목록 정의\n",
    "    columns_to_keep = [\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'depth',\n",
    "        'nst',\n",
    "        'dmin',\n",
    "        'gap',\n",
    "        'Year',      # 1번에서 새로 생성\n",
    "        'Month',     # 1번에서 새로 생성\n",
    "        'magnitude'  # 2번에서 이름 변경\n",
    "    ]\n",
    "\n",
    "    # 4. 위 목록에 있는 컬럼들만 선택하여 새 DataFrame 생성\n",
    "    df_preprocessed = df[columns_to_keep]\n",
    "\n",
    "    # 5. 전처리된 데이터를 새 파일로 저장\n",
    "    output_filename = \"1차 전처리-필요없는 데이터 제거/Test_data.csv\"\n",
    "    df_preprocessed.to_csv(output_filename, index=False)\n",
    "\n",
    "    print(f\"전처리 완료. '{output_filename}'으로 저장했습니다.\")\n",
    "    print(\"\\n--- 최종 컬럼 목록 ---\")\n",
    "    print(df_preprocessed.columns.to_list())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 'query.csv' 파일을 찾을 수 없습니다.\")\n",
    "except KeyError as e:\n",
    "    print(f\"오류: {e.args[0]} 컬럼을 찾을 수 없습니다.\")"
   ],
   "id": "73e0d9303e82329b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 완료. 'Test_data.csv'으로 저장했습니다.\n",
      "\n",
      "--- 최종 컬럼 목록 ---\n",
      "['latitude', 'longitude', 'depth', 'nst', 'dmin', 'gap', 'Year', 'Month', 'magnitude']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T16:37:41.926950Z",
     "start_time": "2025-10-30T16:37:41.916025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "from geopy.point import Point\n",
    "import time\n",
    "\n",
    "# --- 1. 사용자 설정 ---\n",
    "\n",
    "# ⚠️ 여기에 본인의 Google API 키를 입력하세요.\n",
    "# 경고: 이 키를 절대 외부에 노출하거나 공유하지 마세요.\n",
    "API_KEY = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "# 입력 파일 이름\n",
    "INPUT_CSV = 'train_data.csv'\n",
    "\n",
    "# 저장할 파일 이름\n",
    "OUTPUT_CSV = 'train_data_with_elevation.csv'\n",
    "\n",
    "# 반경 몇 km를 확인할지 설정\n",
    "RADIUS_KM = 60\n",
    "\n",
    "# '급경사'로 판단할 고도 차이 (미터)\n",
    "# 예: 60km 반경 내에 2000m(2km) 이상의 고도 차이가 나면 '급경사'로 판단\n",
    "STEEP_SLOPE_THRESHOLD_METERS = 2000\n",
    "\n",
    "# ⚠️ 테스트를 위해 처리할 행 수 (전체 데이터를 돌리기 전에 10개로 테스트)\n",
    "# 전체 데이터를 처리하려면 None 으로 설정\n",
    "PROCESS_LIMIT = None\n",
    "\n",
    "# --- 2. API 및 경사 분석 함수 ---\n",
    "\n",
    "def get_surrounding_points(lat, lon, radius_km):\n",
    "    \"\"\"중심점에서 동서남북 반경 지점의 좌표를 계산합니다.\"\"\"\n",
    "    center_point = Point(lat, lon)\n",
    "    points = {'center': (lat, lon)}\n",
    "\n",
    "    # 북(0), 동(90), 남(180), 서(270)\n",
    "    bearings = [0, 90, 180, 270]\n",
    "    names = ['north', 'east', 'south', 'west']\n",
    "\n",
    "    for name, bearing in zip(names, bearings):\n",
    "        destination = geodesic(kilometers=radius_km).destination(center_point, bearing)\n",
    "        points[name] = (destination.latitude, destination.longitude)\n",
    "\n",
    "    return points\n",
    "\n",
    "def get_elevations_from_api(locations_list, api_key):\n",
    "    \"\"\"\n",
    "    여러 위치의 고도 정보를 Google API로 한 번에 요청합니다.\n",
    "    locations_list: [(lat1, lon1), (lat2, lon2), ...]\n",
    "    \"\"\"\n",
    "    # API가 인식하는 locations 문자열 형식으로 변환 (예: \"lat1,lon1|lat2,lon2\")\n",
    "    locations_str = \"|\".join([f\"{lat},{lon}\" for lat, lon in locations_list])\n",
    "\n",
    "    url = \"https://maps.googleapis.com/maps/api/elevation/json\"\n",
    "    params = {\n",
    "        'locations': locations_str,\n",
    "        'key': api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()  # 오류가 있으면 예외 발생\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    if data['status'] == 'OK':\n",
    "        return data['results']\n",
    "    else:\n",
    "        raise Exception(f\"Google API Error: {data['status']} - {data.get('error_message', '')}\")\n",
    "\n",
    "def analyze_row_elevation(row, api_key, radius_km, slope_threshold):\n",
    "    \"\"\"\n",
    "    DataFrame의 한 행을 받아 is_ocean 과 is_steep_slope 를 분석합니다.\n",
    "    \"\"\"\n",
    "    center_lat = row['latitude']\n",
    "    center_lon = row['longitude']\n",
    "\n",
    "    # 1. 분석할 5개 지점(중심, 동서남북)의 좌표 계산\n",
    "    #    (참고: API는 5개 지점의 고도를 한 번의 요청으로 가져옵니다)\n",
    "    points_to_check = get_surrounding_points(center_lat, center_lon, radius_km)\n",
    "\n",
    "    # API에 보낼 순서 고정: [center, north, east, south, west]\n",
    "    locations_list = [\n",
    "        points_to_check['center'],\n",
    "        points_to_check['north'],\n",
    "        points_to_check['east'],\n",
    "        points_to_check['south'],\n",
    "        points_to_check['west']\n",
    "    ]\n",
    "\n",
    "    # 2. Google API로 5개 지점의 고도 정보 가져오기\n",
    "    elevation_results = get_elevations_from_api(locations_list, api_key)\n",
    "\n",
    "    if len(elevation_results) != 5:\n",
    "        raise Exception(\"API 응답에서 5개의 위치 정보를 받지 못했습니다.\")\n",
    "\n",
    "    # 3. Task 1: \"바다인가?\" (고도가 음수인가?)\n",
    "    # 중심점(첫 번째 결과)의 고도를 확인합니다.\n",
    "    center_elevation = elevation_results[0]['elevation']\n",
    "    is_ocean = center_elevation < 0\n",
    "\n",
    "    # 4. Task 2: \"급경사인가?\"\n",
    "    # 중심점 고도와 주변 4개 지점의 고도를 비교합니다.\n",
    "    is_steep_slope = False\n",
    "    surrounding_elevations = [res['elevation'] for res in elevation_results[1:]] # 4개 지점\n",
    "\n",
    "    for elev in surrounding_elevations:\n",
    "        # 중심 고도와 주변 고도의 차이(절대값)\n",
    "        elevation_diff = abs(center_elevation - elev)\n",
    "\n",
    "        if elevation_diff > slope_threshold:\n",
    "            is_steep_slope = True\n",
    "            break  # 하나라도 급경사면 확인 중단\n",
    "\n",
    "    return pd.Series([is_ocean, is_steep_slope])\n",
    "\n",
    "# --- 3. 메인 스크립트 실행 ---\n",
    "\n",
    "def main():\n",
    "    if API_KEY == \"YOUR_API_KEY_HERE\":\n",
    "        print(\"=\" * 60)\n",
    "        print(\"⚠️ 오류: API_KEY를 스크립트 11번째 줄에 입력해주세요.\")\n",
    "        print(\"Google Cloud Platform에서 'Elevation API'를 활성화해야 합니다.\")\n",
    "        print(\"=\" * 60)\n",
    "        return\n",
    "\n",
    "    print(f\"'{INPUT_CSV}' 파일 읽는 중...\")\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: '{INPUT_CSV}' 파일을 찾을 수 없습니다. 스크립트와 같은 폴더에 있는지 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 처리할 데이터 슬라이싱\n",
    "    if PROCESS_LIMIT is not None:\n",
    "        print(f\"--- 테스트 모드: 처음 {PROCESS_LIMIT}개 행만 처리합니다. ---\")\n",
    "        df_to_process = df.iloc[:PROCESS_LIMIT].copy()\n",
    "    else:\n",
    "        print(\"--- 전체 데이터 처리 모드 ---\")\n",
    "        df_to_process = df.copy()\n",
    "\n",
    "    print(f\"총 {len(df_to_process)}개의 행에 대한 고도 분석을 시작합니다...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # apply 함수를 사용하여 각 행에 분석 함수 적용\n",
    "    try:\n",
    "        new_columns = df_to_process.apply(\n",
    "            analyze_row_elevation,\n",
    "            axis=1,\n",
    "            api_key=API_KEY,\n",
    "            radius_km=RADIUS_KM,\n",
    "            slope_threshold=STEEP_SLOPE_THRESHOLD_METERS\n",
    "        )\n",
    "        new_columns.columns = ['is_ocean', 'is_steep_slope']\n",
    "\n",
    "        # 원본 데이터와 합치기\n",
    "        df_to_process = pd.concat([df_to_process, new_columns], axis=1)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"\\n--- 분석 완료 ---\")\n",
    "        print(f\"총 처리 시간: {end_time - start_time:.2f}초\")\n",
    "\n",
    "        # 결과 미리보기\n",
    "        print(\"\\n분석 결과 미리보기 (is_ocean, is_steep_slope 추가):\")\n",
    "        print(df_to_process.head().to_markdown(index=False))\n",
    "\n",
    "        # 결과 저장\n",
    "        # 원본 파일이 아닌, 처리된 부분만 저장\n",
    "        if PROCESS_LIMIT is not None:\n",
    "            output_file = f\"TEST_{OUTPUT_CSV}\"\n",
    "            print(f\"\\n테스트 결과가 '{output_file}' 파일로 저장되었습니다.\")\n",
    "            df_to_process.to_csv(output_file, index=False)\n",
    "        else:\n",
    "            # 전체 데이터를 처리한 경우, 원본 데이터를 덮어쓰지 않고 새 파일로 저장\n",
    "            # (만약 원본 전체에 추가하고 싶다면 df[new_columns] = ... 로직 필요)\n",
    "            print(f\"\\n전체 분석 결과가 '{OUTPUT_CSV}' 파일로 저장되었습니다.\")\n",
    "            # 원본 df에 새 열을 추가하여 저장\n",
    "            df[['is_ocean', 'is_steep_slope']] = new_columns\n",
    "            df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n--- !!! 처리 중 심각한 오류 발생 !!! ---\")\n",
    "        print(f\"오류: {e}\")\n",
    "        print(\"API 키가 유효한지, Google Cloud 계정에 결제 정보가 등록되었는지,\")\n",
    "        print(\"'Maps Elevation API'가 활성화되었는지 확인하세요.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "10656d1aac0007a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "⚠️ 오류: API_KEY를 스크립트 11번째 줄에 입력해주세요.\n",
      "Google Cloud Platform에서 'Elevation API'를 활성화해야 합니다.\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T16:46:31.854150Z",
     "start_time": "2025-10-30T16:38:49.478001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "from geopy.point import Point\n",
    "import time\n",
    "\n",
    "# --- 1. 사용자 설정 ---\n",
    "\n",
    "# ⚠️ 여기에 본인의 Google API 키를 입력하세요.\n",
    "# 경고: 이 키를 절대 외부에 노출하거나 공유하지 마세요.\n",
    "API_KEY = \"AIzaSyCQt1-_LLhTfX_0l6JAZU1WwlZ1ldkTVTw\"\n",
    "\n",
    "# 입력 파일 이름\n",
    "INPUT_CSV = 'train_data.csv'\n",
    "\n",
    "# 저장할 파일 이름\n",
    "OUTPUT_CSV = 'train_data_with_elevation.csv'\n",
    "\n",
    "# 반경 몇 km를 확인할지 설정\n",
    "RADIUS_KM = 60\n",
    "\n",
    "# '급경사'로 판단할 고도 차이 (미터)\n",
    "# 예: 60km 반경 내에 2000m(2km) 이상의 고도 차이가 나면 '급경사'로 판단\n",
    "STEEP_SLOPE_THRESHOLD_METERS = 2000\n",
    "\n",
    "# ⚠️ 테스트를 위해 처리할 행 수 (전체 데이터를 돌리기 전에 10개로 테스트)\n",
    "# 전체 데이터를 처리하려면 None 으로 설정\n",
    "PROCESS_LIMIT = None\n",
    "\n",
    "# --- 2. API 및 경사 분석 함수 ---\n",
    "\n",
    "def get_surrounding_points(lat, lon, radius_km):\n",
    "    \"\"\"중심점에서 동서남북 반경 지점의 좌표를 계산합니다.\"\"\"\n",
    "    center_point = Point(lat, lon)\n",
    "    points = {'center': (lat, lon)}\n",
    "\n",
    "    # 북(0), 동(90), 남(180), 서(270)\n",
    "    bearings = [0, 90, 180, 270]\n",
    "    names = ['north', 'east', 'south', 'west']\n",
    "\n",
    "    for name, bearing in zip(names, bearings):\n",
    "        destination = geodesic(kilometers=radius_km).destination(center_point, bearing)\n",
    "        points[name] = (destination.latitude, destination.longitude)\n",
    "\n",
    "    return points\n",
    "\n",
    "def get_elevations_from_api(locations_list, api_key):\n",
    "    \"\"\"\n",
    "    여러 위치의 고도 정보를 Google API로 한 번에 요청합니다.\n",
    "    locations_list: [(lat1, lon1), (lat2, lon2), ...]\n",
    "    \"\"\"\n",
    "    # API가 인식하는 locations 문자열 형식으로 변환 (예: \"lat1,lon1|lat2,lon2\")\n",
    "    locations_str = \"|\".join([f\"{lat},{lon}\" for lat, lon in locations_list])\n",
    "\n",
    "    url = \"https://maps.googleapis.com/maps/api/elevation/json\"\n",
    "    params = {\n",
    "        'locations': locations_str,\n",
    "        'key': api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()  # 오류가 있으면 예외 발생\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    if data['status'] == 'OK':\n",
    "        return data['results']\n",
    "    else:\n",
    "        raise Exception(f\"Google API Error: {data['status']} - {data.get('error_message', '')}\")\n",
    "\n",
    "def analyze_row_elevation(row, api_key, radius_km, slope_threshold):\n",
    "    \"\"\"\n",
    "    DataFrame의 한 행을 받아 is_ocean 과 is_steep_slope 를 분석합니다.\n",
    "    \"\"\"\n",
    "    center_lat = row['latitude']\n",
    "    center_lon = row['longitude']\n",
    "\n",
    "    # 1. 분석할 5개 지점(중심, 동서남북)의 좌표 계산\n",
    "    #    (참고: API는 5개 지점의 고도를 한 번의 요청으로 가져옵니다)\n",
    "    points_to_check = get_surrounding_points(center_lat, center_lon, radius_km)\n",
    "\n",
    "    # API에 보낼 순서 고정: [center, north, east, south, west]\n",
    "    locations_list = [\n",
    "        points_to_check['center'],\n",
    "        points_to_check['north'],\n",
    "        points_to_check['east'],\n",
    "        points_to_check['south'],\n",
    "        points_to_check['west']\n",
    "    ]\n",
    "\n",
    "    # 2. Google API로 5개 지점의 고도 정보 가져오기\n",
    "    elevation_results = get_elevations_from_api(locations_list, api_key)\n",
    "\n",
    "    if len(elevation_results) != 5:\n",
    "        raise Exception(\"API 응답에서 5개의 위치 정보를 받지 못했습니다.\")\n",
    "\n",
    "    # 3. Task 1: \"바다인가?\" (고도가 음수인가?)\n",
    "    # 중심점(첫 번째 결과)의 고도를 확인합니다.\n",
    "    center_elevation = elevation_results[0]['elevation']\n",
    "    is_ocean = center_elevation < 0\n",
    "\n",
    "    # 4. Task 2: \"급경사인가?\"\n",
    "    # 중심점 고도와 주변 4개 지점의 고도를 비교합니다.\n",
    "    is_steep_slope = False\n",
    "    surrounding_elevations = [res['elevation'] for res in elevation_results[1:]] # 4개 지점\n",
    "\n",
    "    for elev in surrounding_elevations:\n",
    "        # 중심 고도와 주변 고도의 차이(절대값)\n",
    "        elevation_diff = abs(center_elevation - elev)\n",
    "\n",
    "        if elevation_diff > slope_threshold:\n",
    "            is_steep_slope = True\n",
    "            break  # 하나라도 급경사면 확인 중단\n",
    "\n",
    "    return pd.Series([is_ocean, is_steep_slope])\n",
    "\n",
    "# --- 3. 메인 스크립트 실행 ---\n",
    "\n",
    "def main():\n",
    "    if API_KEY == \"YOUR_API_KEY_HERE\":\n",
    "        print(\"=\" * 60)\n",
    "        print(\"⚠️ 오류: API_KEY를 스크립트 11번째 줄에 입력해주세요.\")\n",
    "        print(\"Google Cloud Platform에서 'Elevation API'를 활성화해야 합니다.\")\n",
    "        print(\"=\" * 60)\n",
    "        return\n",
    "\n",
    "    print(f\"'{INPUT_CSV}' 파일 읽는 중...\")\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: '{INPUT_CSV}' 파일을 찾을 수 없습니다. 스크립트와 같은 폴더에 있는지 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 처리할 데이터 슬라이싱\n",
    "    if PROCESS_LIMIT is not None:\n",
    "        print(f\"--- 테스트 모드: 처음 {PROCESS_LIMIT}개 행만 처리합니다. ---\")\n",
    "        df_to_process = df.iloc[:PROCESS_LIMIT].copy()\n",
    "    else:\n",
    "        print(\"--- 전체 데이터 처리 모드 ---\")\n",
    "        df_to_process = df.copy()\n",
    "\n",
    "    print(f\"총 {len(df_to_process)}개의 행에 대한 고도 분석을 시작합니다...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # apply 함수를 사용하여 각 행에 분석 함수 적용\n",
    "    try:\n",
    "        new_columns = df_to_process.apply(\n",
    "            analyze_row_elevation,\n",
    "            axis=1,\n",
    "            api_key=API_KEY,\n",
    "            radius_km=RADIUS_KM,\n",
    "            slope_threshold=STEEP_SLOPE_THRESHOLD_METERS\n",
    "        )\n",
    "        new_columns.columns = ['is_ocean', 'is_steep_slope']\n",
    "\n",
    "        # 원본 데이터와 합치기\n",
    "        df_to_process = pd.concat([df_to_process, new_columns], axis=1)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"\\n--- 분석 완료 ---\")\n",
    "        print(f\"총 처리 시간: {end_time - start_time:.2f}초\")\n",
    "\n",
    "        # 결과 미리보기\n",
    "        print(\"\\n분석 결과 미리보기 (is_ocean, is_steep_slope 추가):\")\n",
    "        print(df_to_process.head().to_markdown(index=False))\n",
    "\n",
    "        # 결과 저장\n",
    "        # 원본 파일이 아닌, 처리된 부분만 저장\n",
    "        if PROCESS_LIMIT is not None:\n",
    "            output_file = f\"TEST_{OUTPUT_CSV}\"\n",
    "            print(f\"\\n테스트 결과가 '{output_file}' 파일로 저장되었습니다.\")\n",
    "            df_to_process.to_csv(output_file, index=False)\n",
    "        else:\n",
    "            # 전체 데이터를 처리한 경우, 원본 데이터를 덮어쓰지 않고 새 파일로 저장\n",
    "            # (만약 원본 전체에 추가하고 싶다면 df[new_columns] = ... 로직 필요)\n",
    "            print(f\"\\n전체 분석 결과가 '{OUTPUT_CSV}' 파일로 저장되었습니다.\")\n",
    "            # 원본 df에 새 열을 추가하여 저장\n",
    "            df[['is_ocean', 'is_steep_slope']] = new_columns\n",
    "            df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n--- !!! 처리 중 심각한 오류 발생 !!! ---\")\n",
    "        print(f\"오류: {e}\")\n",
    "        print(\"API 키가 유효한지, Google Cloud 계정에 결제 정보가 등록되었는지,\")\n",
    "        print(\"'Maps Elevation API'가 활성화되었는지 확인하세요.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "627f4926cb8c7551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_data.csv' 파일 읽는 중...\n",
      "--- 전체 데이터 처리 모드 ---\n",
      "총 782개의 행에 대한 고도 분석을 시작합니다...\n",
      "\n",
      "--- 분석 완료 ---\n",
      "총 처리 시간: 462.36초\n",
      "\n",
      "분석 결과 미리보기 (is_ocean, is_steep_slope 추가):\n",
      "|   magnitude |   nst |   dmin |   gap |   depth |   latitude |   longitude |   Year |   Month |   tsunami | is_ocean   | is_steep_slope   |\n",
      "|------------:|------:|-------:|------:|--------:|-----------:|------------:|-------:|--------:|----------:|:-----------|:-----------------|\n",
      "|         7   |   117 |  0.509 |    17 |  14     |    -9.7963 |     159.596 |   2022 |      11 |         1 | True       | True             |\n",
      "|         6.9 |    99 |  2.229 |    34 |  25     |    -4.9559 |     100.738 |   2022 |      11 |         0 | True       | True             |\n",
      "|         7   |   147 |  3.125 |    18 | 579     |   -20.0508 |    -178.346 |   2022 |      11 |         1 | True       | True             |\n",
      "|         7.3 |   149 |  1.865 |    21 |  37     |   -19.2918 |    -172.129 |   2022 |      11 |         1 | True       | True             |\n",
      "|         6.6 |   131 |  4.998 |    27 | 624.464 |   -25.5948 |     178.278 |   2022 |      11 |         1 | True       | False            |\n",
      "\n",
      "전체 분석 결과가 'train_data_with_elevation.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 파일 읽기\n",
    "try:\n",
    "    df = pd.read_csv('train_data_with_elevation.csv')\n",
    "    print(\"파일 읽기 성공:\")\n",
    "    print(df.head()[['is_ocean', 'is_steep_slope']].to_markdown(index=False))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 'train_data_with_elevation.csv' 파일을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# 2. 'is_ocean'과 'is_steep_slope' 열을 정수(int)로 변환\n",
    "#   (True -> 1, False -> 0)\n",
    "if 'is_ocean' in df.columns:\n",
    "    df['is_ocean'] = df['is_ocean'].astype(int)\n",
    "    print(\"\\n'is_ocean' 열을 정수로 변환했습니다.\")\n",
    "else:\n",
    "    print(\"\\n경고: 'is_ocean' 열이 없습니다.\")\n",
    "\n",
    "if 'is_steep_slope' in df.columns:\n",
    "    df['is_steep_slope'] = df['is_steep_slope'].astype(int)\n",
    "    print(\"'is_steep_slope' 열을 정수로 변환했습니다.\")\n",
    "else:\n",
    "    print(\"\\n경고: 'is_steep_slope' 열이 없습니다.\")\n",
    "\n",
    "\n",
    "# 3. 변경된 결과 확인\n",
    "print(\"\\n--- 변환 후 데이터 확인 (head) ---\")\n",
    "print(df.head()[['is_ocean', 'is_steep_slope']].to_markdown(index=False))\n",
    "\n",
    "\n",
    "# 4. 새 파일로 저장\n",
    "output_filename = 'train_data_processed.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\n변환된 데이터를 '{output_filename}' 파일로 저장했습니다.\")"
   ],
   "id": "e65d3a1b4d3f6f9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
