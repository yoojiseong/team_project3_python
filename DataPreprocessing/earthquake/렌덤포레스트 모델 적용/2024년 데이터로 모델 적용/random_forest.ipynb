{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T14:32:17.191442Z",
     "start_time": "2025-11-05T14:32:16.167175Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split # 데이터 분리를 위해 추가\n",
    "from sklearn.metrics import accuracy_score         # 정확도 계산을 위해 추가\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "print(\"--- 1. 라이브러리 임포트 ---\")\n",
    "\n",
    "# 1. 데이터 로드\n",
    "# 파일 경로를 이전에 생성한 파일로 수정했습니다.\n",
    "file_path = 'final_2024_processed_data.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"--- 2. '{file_path}' 데이터 로드 완료 ---\")\n",
    "    print(f\"원본 데이터 크기: {df.shape}\")\n",
    "\n",
    "    # 2. 데이터 전처리: NaN 값 처리 및 타겟 변수 정수형 변환\n",
    "    # 모델 학습을 위해 NaN 값을 가진 행을 제거합니다.\n",
    "    df.dropna(inplace=True)\n",
    "    print(f\"--- 3. NaN 값 제거 후 데이터 크기: {df.shape} ---\")\n",
    "\n",
    "    # 'tsunami' 컬럼을 분류에 적합한 정수형(int)으로 변환합니다.\n",
    "    df['tsunami'] = df['tsunami'].astype(int)\n",
    "    print(\"--- 4. 'tsunami' 컬럼을 정수형(int)으로 변환 ---\")\n",
    "\n",
    "    # 3. 특징(X)과 타겟(y) 변수 분리\n",
    "    X = df.drop('tsunami', axis=1)\n",
    "    y = df['tsunami']\n",
    "    print(\"--- 5. 특징(X)과 타겟(y) 분리 완료 ---\")\n",
    "\n",
    "    # 데이터가 비어 있는지 확인\n",
    "    if X.empty or y.empty:\n",
    "        print(\"오류: NaN 값을 제거한 후 데이터가 남아있지 않습니다.\")\n",
    "        sys.exit()\n",
    "\n",
    "    # 타겟 클래스가 2개 이상인지 확인 (분류를 위해)\n",
    "    if y.nunique() < 2:\n",
    "        print(\"경고: 타겟 클래스가 1개뿐입니다. stratify 없이 분할합니다.\")\n",
    "        stratify_param = None\n",
    "    else:\n",
    "        stratify_param = y\n",
    "\n",
    "\n",
    "    # 4. 학습 데이터와 테스트 데이터 분리 (★ 추가된 부분)\n",
    "    # 모델을 평가하기 위해 데이터를 학습용(80%)과 테스트용(20%)으로 분리합니다.\n",
    "    # stratify=y : 타겟(y)의 클래스 비율을 유지하면서 데이터를 나눕니다.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,    # 20%를 테스트용으로 사용\n",
    "        random_state=42,  # 결과를 동일하게 재현하기 위함\n",
    "        stratify=stratify_param # 'tsunami' 비율을 맞춤\n",
    "    )\n",
    "    print(f\"--- 6. 데이터 분리 완료 (학습용: {X_train.shape[0]}개, 테스트용: {X_test.shape[0]}개) ---\")\n",
    "\n",
    "    # 5. RandomForest 분류기 모델 초기화\n",
    "    model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    print(\"--- 7. RandomForest 모델 초기화 완료 ---\")\n",
    "\n",
    "    # 6. 모델 학습 (★ 수정된 부분: 학습용 데이터로 학습)\n",
    "    # X(특징)와 y(타겟) 데이터를 사용하여 모델을 학습시킵니다.\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"--- 8. 모델 학습 완료 ---\")\n",
    "\n",
    "    # 7. 모델 평가 및 정확도 출력 (★ 추가된 부분)\n",
    "    # 테스트 데이터로 예측을 수행합니다.\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 정확도를 계산합니다.\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n--- 9. 모델 평가 (정확도) ---\")\n",
    "    print(f\"테스트 데이터 정확도: {accuracy * 100:.2f}%\") # 정확도를 퍼센트로 출력\n",
    "\n",
    "    # 8. 학습된 모델을 파일로 저장\n",
    "    model_filename = 'random_forest_tsunami_model.joblib'\n",
    "    joblib.dump(model, model_filename)\n",
    "\n",
    "    print(f\"\\n[최종 완료] 모델이 '{model_filename}' 파일로 성공적으로 저장되었습니다.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{file_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인하세요.\")\n",
    "except KeyError:\n",
    "    print(\"오류: 'tsunami' 컬럼을 찾을 수 없습니다. 원본 파일의 컬럼을 확인하세요.\")\n",
    "except ValueError as e:\n",
    "    print(f\"데이터 처리 중 오류가 발생했습니다: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"예상치 못한 오류가 발생했습니다: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 라이브러리 임포트 ---\n",
      "--- 2. 'final_2024_processed_data.csv' 데이터 로드 완료 ---\n",
      "원본 데이터 크기: (5872, 6)\n",
      "--- 3. NaN 값 제거 후 데이터 크기: (5872, 6) ---\n",
      "--- 4. 'tsunami' 컬럼을 정수형(int)으로 변환 ---\n",
      "--- 5. 특징(X)과 타겟(y) 분리 완료 ---\n",
      "--- 6. 데이터 분리 완료 (학습용: 4697개, 테스트용: 1175개) ---\n",
      "--- 7. RandomForest 모델 초기화 완료 ---\n",
      "--- 8. 모델 학습 완료 ---\n",
      "\n",
      "--- 9. 모델 평가 (정확도) ---\n",
      "테스트 데이터 정확도: 98.72%\n",
      "\n",
      "[최종 완료] 모델이 'random_forest_tsunami_model.joblib' 파일로 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
