{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import time\n",
    "import obspy\n",
    "import numpy as np\n",
    "\n",
    "# 0. ë²„ì „ í™•ì¸ (1.4.2ê°€ ë‚˜ì™€ì•¼ í•¨)\n",
    "print(f\"--- í˜„ì¬ obspy ë²„ì „: {obspy.__version__} ---\")\n",
    "\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "# --- 1. 2024ë…„ë„ ì§€ì§„ 'ê²€ìƒ‰' ---\n",
    "# (IDë¥¼ ëª¨ë¥´ë¯€ë¡œ, 2024ë…„ 1ì›” 1ì¼ ì¼ë³¸ ë…¸í†  ë°˜ë„ ì§€ì§„(M7.5)ì„ ê²€ìƒ‰)\n",
    "print(\"--- 1. 2024ë…„ 1ì›” 1ì¼ (M3.0+) ì§€ì§„ ê²€ìƒ‰ ì¤‘... ---\")\n",
    "search_start = UTCDateTime(\"2024-01-01T00:00:00\")\n",
    "search_end = UTCDateTime(\"2024-01-02T00:00:00\") # 1ì›” 1ì¼ í•˜ë£¨ ë™ì•ˆ\n",
    "\n",
    "origin_time = None\n",
    "event_lat = None\n",
    "event_lon = None\n",
    "event_id_str = \"N/A\"\n",
    "\n",
    "try:\n",
    "    cat = client.get_events(\n",
    "        starttime=search_start,\n",
    "        endtime=search_end,\n",
    "        minmagnitude=3.0 # M7.0 ì´ìƒë§Œ ê²€ìƒ‰\n",
    "    )\n",
    "\n",
    "    if not cat:\n",
    "        print(\"  > 2024ë…„ 1ì›” 1ì¼ì— M3.0+ ì§€ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"  > ë‹¤ë¥¸ ë‚ ì§œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.\")\n",
    "        exit()\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ì²« ë²ˆì§¸ ì´ë²¤íŠ¸(ê°€ì¥ í° ì´ë²¤íŠ¸)ë¥¼ ì‚¬ìš©\n",
    "    event = cat[0]\n",
    "\n",
    "    # íŒŒí˜• ìˆ˜ì§‘ì— í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ\n",
    "    origin_time = event.origins[0].time\n",
    "    event_lat = event.origins[0].latitude\n",
    "    event_lon = event.origins[0].longitude\n",
    "    event_mag = event.magnitudes[0].mag\n",
    "    # event.resource_idëŠ” ê°ì²´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ .id ì†ì„± í™•ì¸\n",
    "    event_id_str = event.resource_id.id if event.resource_id else \"ID_NOT_FOUND\"\n",
    "\n",
    "    print(f\"  > ê²€ìƒ‰ëœ ì´ë²¤íŠ¸: {event.event_descriptions[0].text}\")\n",
    "    print(f\"  > Event ID: {event_id_str}\")\n",
    "    print(f\"  > ë°œìƒ ì‹œê° (UTC): {origin_time}\")\n",
    "    print(f\"  > ê·œëª¨: {event_mag}\")\n",
    "    print(f\"  > ìœ„ì¹˜: {event_lat}, {event_lon}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  > get_events() ì˜¤ë¥˜ (ì´ë²¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨): {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. 'íŒŒí˜•(Waveform)' ë°ì´í„° ìˆ˜ì§‘ ---\n",
    "# (1ë‹¨ê³„ì—ì„œ ì°¾ì€ ì‹œê°„, ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒí˜•ì„ ìš”ì²­)\n",
    "\n",
    "print(f\"\\n--- 2. '{event_id_str}'ì˜ íŒŒí˜•(Waveform) ë°ì´í„° ìˆ˜ì§‘ ì‹œë„... ---\")\n",
    "print(\"(ì¡°ê±´: ë°œìƒ í›„ 10ë¶„ê°„, ì§„ì•™ 5ë„ ì´ë‚´, BH? ì±„ë„)\")\n",
    "\n",
    "st = None # íŒŒí˜• ë¬¶ìŒ (Stream)\n",
    "\n",
    "try:\n",
    "    st = client.get_waveforms(\n",
    "        network=\"*\",        # ëª¨ë“  ë„¤íŠ¸ì›Œí¬\n",
    "        station=\"*\",      # ëª¨ë“  ê´€ì¸¡ì†Œ\n",
    "        location=\"*\",     # ëª¨ë“  ìœ„ì¹˜ ì½”ë“œ\n",
    "        channel=\"BH?\",      # ê´‘ëŒ€ì—­ ì±„ë„ (BHZ, BHN, BHE)\n",
    "        starttime=origin_time,              # 1. ê²€ìƒ‰ëœ ì§€ì§„ ë°œìƒ ì‹œê°\n",
    "        endtime=origin_time + 600,          # 10ë¶„(600ì´ˆ) ë™ì•ˆ\n",
    "        latitude=event_lat,                 # 2. ê²€ìƒ‰ëœ ìœ„ë„\n",
    "        longitude=event_lon,                # 3. ê²€ìƒ‰ëœ ê²½ë„\n",
    "        maxradius=5.0                       # ë°˜ê²½ 5ë„ ì´ë‚´\n",
    "    )\n",
    "\n",
    "    if st:\n",
    "        print(f\"\\n--- 3. íŒŒí˜• ìˆ˜ì§‘ ì„±ê³µ! ---\")\n",
    "        print(f\"  > ì´ {len(st)} ê°œì˜ íŒŒí˜•(ì±„ë„)ì„ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        # --- 4. \"ìˆ˜ì¹˜í™”ëœ ë°ì´í„°\" (Number Array) í™•ì¸ ---\n",
    "        print(\"\\n--- 4. 'ìˆ˜ì¹˜í™”ëœ ë°ì´í„°' (ìˆ«ì ë°°ì—´) í™•ì¸ ---\")\n",
    "\n",
    "        tr = st[0] # ì²« ë²ˆì§¸ íŒŒí˜•ì„ ìƒ˜í”Œë¡œ í™•ì¸\n",
    "        print(f\"  > ì²« ë²ˆì§¸ íŒŒí˜• ID: {tr.id}\")\n",
    "\n",
    "        # <<< ì´ê²ƒì´ ë°”ë¡œ ëª¨ë¸ì— ë„£ì„ \"ìˆ«ì ë°°ì—´\"ì…ë‹ˆë‹¤ >>>\n",
    "        number_array = tr.data\n",
    "\n",
    "        print(f\"  > ì´ íŒŒí˜•ì˜ ì´ ìˆ«ì ê°œìˆ˜: {len(number_array)} ê°œ\")\n",
    "        print(f\"  > ì‹¤ì œ ìˆ«ì ë°°ì—´ (ì• 10ê°œ): {number_array[:10]}\")\n",
    "\n",
    "        # --- 5. íŠ¹ì§•(Feature) ê³„ì‚° ì˜ˆì‹œ ---\n",
    "        print(\"\\n--- 5. ì´ 'ìˆ«ì ë°°ì—´'ë¡œ íŠ¹ì§•(Feature) ê³„ì‚°í•˜ê¸° (ì˜ˆì‹œ) ---\")\n",
    "\n",
    "        max_amplitude = np.max(np.abs(number_array))\n",
    "\n",
    "        print(f\"  > (ì˜ˆì‹œ íŠ¹ì§•) ìµœëŒ€ ì§„í­ (Max Amplitude): {max_amplitude:.2f}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\n--- 3. ìˆ˜ì§‘ ì‹¤íŒ¨ (ë°ì´í„° ì—†ìŒ) ---\")\n",
    "        print(\"  > ì´ ì¡°ê±´(2024ë…„ 1ì›” 1ì¼)ì— ë§ëŠ” íŒŒí˜• ë°ì´í„°ê°€ ì„œë²„ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "except AttributeError as ae:\n",
    "    print(f\"\\n--- !!! ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ (AttributeError) !!! ---\")\n",
    "    print(f\"  > ì˜¤ë¥˜: {ae}\")\n",
    "    print(f\"  > ì›ì¸: 'obspy.Client'ê°€ 'get_waveforms' í•¨ìˆ˜ë„ ì°¾ì§€ ëª»í•©ë‹ˆë‹¤.\")\n",
    "    print(f\"  > í•´ê²°: Python 3.11 ê°€ìƒí™˜ê²½ í´ë”(venv)ë¥¼ ì‚­ì œí•˜ê³  2ë‹¨ê³„ë¶€í„° ë‹¤ì‹œ ì‹œë„í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- !!! ì˜¤ë¥˜ ë°œìƒ !!! ---\")\n",
    "    print(f\"  > ì˜¤ë¥˜: {e}\")\n",
    "    if \"No data available\" in str(e) or \"204\" in str(e):\n",
    "        print(\"  > (ì›ì¸: ì´ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì„œë²„ì— ì—†ìŠµë‹ˆë‹¤.)\")\n",
    "    else:\n",
    "        print(\"  > (ì›ì¸: ê·¸ ì™¸ ì˜¤ë¥˜. ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\")"
   ],
   "id": "c8b6fb9da9f519de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import time\n",
    "import obspy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(f\"--- í˜„ì¬ obspy ë²„ì „: {obspy.__version__} ---\")\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "# --- 1. 2024ë…„ë„ ì§€ì§„ 'ê²€ìƒ‰' ---\n",
    "print(\"--- 1. 2024ë…„ 1ì›” 1ì¼ (M3.0+) ì§€ì§„ ê²€ìƒ‰ ì¤‘... ---\")\n",
    "search_start = UTCDateTime(\"2024-02-01T00:00:00\")\n",
    "search_end = UTCDateTime(\"2024-03-01T00:00:00\")\n",
    "min_mag = 3.0\n",
    "\n",
    "results_list = []\n",
    "\n",
    "try:\n",
    "    cat = client.get_events(\n",
    "        starttime=search_start,\n",
    "        endtime=search_end,\n",
    "        minmagnitude=min_mag\n",
    "    )\n",
    "    if not cat:\n",
    "        print(f\"  > {search_start.date}ì— M{min_mag}+ ì§€ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"  > ì´ {len(cat)} ê°œì˜ M{min_mag}+ ì§€ì§„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. íŒŒí˜• ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # --- 2. 'ëª¨ë“ ' ì§€ì§„ì„ ìˆœíšŒ ---\n",
    "    for i, event in enumerate(cat):\n",
    "\n",
    "        event_time = None\n",
    "        event_lat = None\n",
    "        event_lon = None\n",
    "        event_mag = None\n",
    "        event_depth_km = None\n",
    "        event_id_str = \"N/A\"\n",
    "\n",
    "        # ê²€ìƒ‰í•  ë°˜ê²½ (ë‹¨ìœ„: ë„)\n",
    "        search_radius_deg = 2.0\n",
    "\n",
    "        try:\n",
    "            # --- 3. ê¸°ë³¸ ì§€ì§„ ì •ë³´ ì¶”ì¶œ ---\n",
    "            origin = event.origins[0]\n",
    "            event_time = origin.time\n",
    "            event_lat = origin.latitude\n",
    "            event_lon = origin.longitude\n",
    "            event_depth_km = origin.depth / 1000.0 if origin.depth else 0.0\n",
    "            event_mag = event.magnitudes[0].mag if event.magnitudes else 0.0\n",
    "\n",
    "            if event.resource_id:\n",
    "                event_id_str = str(event.resource_id.id).split('=')[-1]\n",
    "            else:\n",
    "                event_id_str = f\"event_{i}\"\n",
    "\n",
    "            print(f\"\\n--- [{i+1}/{len(cat)}] ì´ë²¤íŠ¸ ì²˜ë¦¬ ì¤‘ (ID: {event_id_str}, Mag: {event_mag}) ---\")\n",
    "\n",
    "            # --- 4. (!!! ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ 1 !!!) ---\n",
    "            # ë¨¼ì € ì§€ì§„ ê·¼ì²˜ì˜ 'ê´€ì¸¡ì†Œ(Station)' ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "            print(f\"  > 4a. ë°˜ê²½ {search_radius_deg}ë„ ì´ë‚´ì˜ ê´€ì¸¡ì†Œ ê²€ìƒ‰ ì¤‘...\")\n",
    "\n",
    "            stations_inventory = client.get_stations(\n",
    "                starttime=event_time,\n",
    "                endtime=event_time + 300, # 5ë¶„\n",
    "                latitude=event_lat,       # get_stationsëŠ” ì´ íŒŒë¼ë¯¸í„°ê°€ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "                longitude=event_lon,\n",
    "                maxradius=search_radius_deg,\n",
    "                level=\"station\"\n",
    "            )\n",
    "\n",
    "            if not stations_inventory or len(stations_inventory) == 0:\n",
    "                print(\"  > ê·¼ì²˜ì— ê´€ì¸¡ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë°ì´í„° ì—†ìŒ). ë‹¤ìŒ ì´ë²¤íŠ¸ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\")\n",
    "                continue\n",
    "\n",
    "            # ê´€ì¸¡ì†Œ ëª©ë¡ì—ì„œ 'ë„¤íŠ¸ì›Œí¬'ì™€ 'ê´€ì¸¡ì†Œ' ì½”ë“œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "            network_codes = set()\n",
    "            station_codes = set()\n",
    "            for network in stations_inventory:\n",
    "                network_codes.add(network.code)\n",
    "                for station in network:\n",
    "                    station_codes.add(station.code)\n",
    "\n",
    "            if not station_codes:\n",
    "                 print(\"  > ê´€ì¸¡ì†Œ ì½”ë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì´ë²¤íŠ¸ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\")\n",
    "                 continue\n",
    "\n",
    "            # ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë³€í™˜ (e.g., \"JP,KR\", \"HON,INU\")\n",
    "            net_str = \",\".join(network_codes)\n",
    "            sta_str = \",\".join(station_codes)\n",
    "\n",
    "            print(f\"  > 4b. ì°¾ì€ ê´€ì¸¡ì†Œ({len(station_codes)}ê°œ)ì˜ íŒŒí˜• ìš”ì²­ ì¤‘...\")\n",
    "\n",
    "            # --- 5. (!!! ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ 2 !!!) ---\n",
    "            # 'minlatitude' ëŒ€ì‹  'network', 'station' ì½”ë“œë¡œ íŒŒí˜• ìš”ì²­\n",
    "            st = client.get_waveforms(\n",
    "                network=net_str,    # (ìˆ˜ì •) ë„¤íŠ¸ì›Œí¬ ì½”ë“œë¡œ í•„í„°\n",
    "                station=sta_str,    # (ìˆ˜ì •) ê´€ì¸¡ì†Œ ì½”ë“œë¡œ í•„í„°\n",
    "                location=\"*\",\n",
    "                channel=\"BHZ\",\n",
    "                starttime=event_time,\n",
    "                endtime=event_time + 300\n",
    "                # (ì‚­ì œ) minlatitude, maxlatitude, minlongitude, maxlongitude\n",
    "            )\n",
    "\n",
    "            max_amplitude = 0.0\n",
    "\n",
    "            if st:\n",
    "                max_amps_per_station = [np.max(np.abs(tr.data)) for tr in st if len(tr.data) > 0]\n",
    "                if max_amps_per_station:\n",
    "                    max_amplitude = np.max(max_amps_per_station)\n",
    "                print(f\"  > íŒŒí˜• ìˆ˜ì§‘ ì„±ê³µ. ìµœëŒ€ ì§„í­ (Max Amp): {max_amplitude:.2f}\")\n",
    "            else:\n",
    "                print(f\"  > ì´ ì´ë²¤íŠ¸ì˜ íŒŒí˜• ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (No data available).\")\n",
    "\n",
    "            # --- 6. CSV ì €ì¥ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ì— 'ê²°ê³¼' ì¶”ê°€ ---\n",
    "            results_list.append({\n",
    "                \"event_id\": event_id_str,\n",
    "                \"time_utc\": event_time.isoformat(),\n",
    "                \"latitude\": event_lat,\n",
    "                \"longitude\": event_lon,\n",
    "                \"magnitude\": event_mag,\n",
    "                \"depth_km\": event_depth_km,\n",
    "                \"max_amplitude_bhz\": max_amplitude\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # ë§Œì•½ get_stations()ì—ì„œë„ 'latitude' ì˜¤ë¥˜ê°€ ë‚œë‹¤ë©´, obspy.Client ìì²´ê°€ ì™„ì „íˆ ê³ ì¥ ë‚œ ê²ƒì…ë‹ˆë‹¤.\n",
    "            print(f\"  > ì´ë²¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  > get_events() ì˜¤ë¥˜ (ì´ë²¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨): {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„, ë¦¬ìŠ¤íŠ¸ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜ ---\n",
    "print(\"\\n--- 7. ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ. CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ---\")\n",
    "\n",
    "if results_list:\n",
    "    df = pd.DataFrame(results_list)\n",
    "    output_filename = f\"earthquake_features_{search_start.date}.csv\"\n",
    "    output_path = os.path.join(os.getcwd(), output_filename)\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"  > ì„±ê³µ! ì´ {len(df)} ê°œì˜ ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼\")\n",
    "    print(f\"  > '{output_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"\\n[CSV ìƒ˜í”Œ ë°ì´í„°]\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"  > ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  ì´ë²¤íŠ¸ì—ì„œ íŒŒí˜• ìˆ˜ì§‘ ì‹¤íŒ¨)\")\n",
    "\n",
    "print(\"\\n--- ì‘ì—… ì¢…ë£Œ ---\")"
   ],
   "id": "f7065cb8452c80e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import time\n",
    "import obspy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(f\"--- í˜„ì¬ obspy ë²„ì „: {obspy.__version__} ---\")\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "# --- 1. 2024ë…„ë„ ì§€ì§„ 'ê²€ìƒ‰' ---\n",
    "print(\"--- 1. 2024ë…„ 1ì›” 1ì¼ (M3.0+) ì§€ì§„ ê²€ìƒ‰ ì¤‘... ---\")\n",
    "search_start = UTCDateTime(\"2024-01-01T00:00:00\")\n",
    "search_end = UTCDateTime(\"2024-01-02T00:00:00\")\n",
    "min_mag = 3.0\n",
    "\n",
    "results_list = []\n",
    "\n",
    "try:\n",
    "    # (ìˆ˜ì •) ì“°ë‚˜ë¯¸ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆë„ë¡ includeall=True ì¶”ê°€\n",
    "    cat = client.get_events(\n",
    "        starttime=search_start,\n",
    "        endtime=search_end,\n",
    "        minmagnitude=min_mag,\n",
    "        includeallorigins=True # í˜¹ì‹œ ëª¨ë¥¼ ìƒì„¸ ì •ë³´ë¥¼ ìœ„í•´\n",
    "    )\n",
    "    if not cat:\n",
    "        print(f\"  > {search_start.date}ì— M{min_mag}+ ì§€ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"  > ì´ {len(cat)} ê°œì˜ M{min_mag}+ ì§€ì§„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. íŒŒí˜• ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # --- 2. 'ëª¨ë“ ' ì§€ì§„ì„ ìˆœíšŒ ---\n",
    "    for i, event in enumerate(cat):\n",
    "\n",
    "        event_time = None\n",
    "        event_lat = None\n",
    "        event_lon = None\n",
    "        event_mag = None\n",
    "        event_depth_km = None\n",
    "        event_id_str = \"N/A\"\n",
    "\n",
    "        search_radius_deg = 2.0\n",
    "\n",
    "        try:\n",
    "            # --- 3. ê¸°ë³¸ ì§€ì§„ ì •ë³´ ì¶”ì¶œ ---\n",
    "            origin = event.origins[0]\n",
    "            event_time = origin.time\n",
    "            event_lat = origin.latitude\n",
    "            event_lon = origin.longitude\n",
    "            event_depth_km = origin.depth / 1000.0 if origin.depth else 0.0\n",
    "            event_mag = event.magnitudes[0].mag if event.magnitudes else 0.0\n",
    "\n",
    "            if event.resource_id:\n",
    "                event_id_str = str(event.resource_id.id).split('=')[-1]\n",
    "            else:\n",
    "                event_id_str = f\"event_{i}\"\n",
    "\n",
    "            print(f\"\\n--- [{i+1}/{len(cat)}] ì´ë²¤íŠ¸ ì²˜ë¦¬ ì¤‘ (ID: {event_id_str}, Mag: {event_mag}) ---\")\n",
    "\n",
    "            # --- (!!! ì—¬ê¸°ê°€ ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„ !!!) ---\n",
    "            # --- 4. ì“°ë‚˜ë¯¸ ì •ë³´ í™•ì¸ ---\n",
    "            tsunami_flag = 0 # 0 = ì“°ë‚˜ë¯¸ ì•„ë‹˜, 1 = ì“°ë‚˜ë¯¸ ê°€ëŠ¥ì„±\n",
    "\n",
    "            # 4a. ì´ë²¤íŠ¸ íƒ€ì… í™•ì¸\n",
    "            if event.event_type == \"tsunami\":\n",
    "                tsunami_flag = 1\n",
    "\n",
    "            # 4b. ì´ë²¤íŠ¸ ì„¤ëª…(description) í…ìŠ¤íŠ¸ í™•ì¸\n",
    "            if tsunami_flag == 0 and event.event_descriptions:\n",
    "                for desc in event.event_descriptions:\n",
    "                    if \"tsunami\" in desc.text.lower():\n",
    "                        tsunami_flag = 1\n",
    "                        break # 'tsunami' ë‹¨ì–´ë¥¼ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨\n",
    "\n",
    "            if tsunami_flag == 1:\n",
    "                print(\"  > !!! ì“°ë‚˜ë¯¸(tsunami) í‚¤ì›Œë“œ ë°œê²¬! !!!\")\n",
    "            # --- (ì¶”ê°€ ë) ---\n",
    "\n",
    "\n",
    "            # --- 5. ê·¼ì²˜ 'ê´€ì¸¡ì†Œ(Station)' ëª©ë¡ ê²€ìƒ‰ ---\n",
    "            print(f\"  > 5a. ë°˜ê²½ {search_radius_deg}ë„ ì´ë‚´ì˜ ê´€ì¸¡ì†Œ ê²€ìƒ‰ ì¤‘...\")\n",
    "\n",
    "            stations_inventory = client.get_stations(\n",
    "                starttime=event_time,\n",
    "                endtime=event_time + 300,\n",
    "                latitude=event_lat,\n",
    "                longitude=event_lon,\n",
    "                maxradius=search_radius_deg,\n",
    "                level=\"station\"\n",
    "            )\n",
    "\n",
    "            if not stations_inventory or len(stations_inventory) == 0:\n",
    "                print(\"  > ê·¼ì²˜ì— ê´€ì¸¡ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë°ì´í„° ì—†ìŒ).\")\n",
    "                # (ìˆ˜ì •) ê´€ì¸¡ì†Œê°€ ì—†ì–´ë„ ì§€ì§„ ì •ë³´(ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ í¬í•¨)ëŠ” ì €ì¥\n",
    "                max_amplitude = 0.0 # íŒŒí˜•ì´ ì—†ìœ¼ë¯€ë¡œ 0\n",
    "\n",
    "            else:\n",
    "                # --- 6. íŒŒí˜•(Waveform) ë°ì´í„° ìˆ˜ì§‘ ---\n",
    "                network_codes = {net.code for net in stations_inventory}\n",
    "                station_codes = {sta.code for net in stations_inventory for sta in net}\n",
    "\n",
    "                net_str = \",\".join(network_codes)\n",
    "                sta_str = \",\".join(station_codes)\n",
    "\n",
    "                print(f\"  > 6b. ì°¾ì€ ê´€ì¸¡ì†Œ({len(station_codes)}ê°œ)ì˜ íŒŒí˜• ìš”ì²­ ì¤‘...\")\n",
    "\n",
    "                st = client.get_waveforms(\n",
    "                    network=net_str,\n",
    "                    station=sta_str,\n",
    "                    location=\"*\",\n",
    "                    channel=\"BHZ\",\n",
    "                    starttime=event_time,\n",
    "                    endtime=event_time + 300\n",
    "                )\n",
    "\n",
    "                max_amplitude = 0.0\n",
    "\n",
    "                if st:\n",
    "                    max_amps_per_station = [np.max(np.abs(tr.data)) for tr in st if len(tr.data) > 0]\n",
    "                    if max_amps_per_station:\n",
    "                        max_amplitude = np.max(max_amps_per_station)\n",
    "                    print(f\"  > íŒŒí˜• ìˆ˜ì§‘ ì„±ê³µ. ìµœëŒ€ ì§„í­ (Max Amp): {max_amplitude:.2f}\")\n",
    "                else:\n",
    "                    print(f\"  > ì´ ì´ë²¤íŠ¸ì˜ íŒŒí˜• ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (No data available).\")\n",
    "\n",
    "            # --- 7. CSV ì €ì¥ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ì— 'ê²°ê³¼' ì¶”ê°€ ---\n",
    "            results_list.append({\n",
    "                \"event_id\": event_id_str,\n",
    "                \"time_utc\": event_time.isoformat(),\n",
    "                \"latitude\": event_lat,\n",
    "                \"longitude\": event_lon,\n",
    "                \"magnitude\": event_mag,\n",
    "                \"depth_km\": event_depth_km,\n",
    "                \"max_amplitude_bhz\": max_amplitude,\n",
    "                \"tsunami_flag\": tsunami_flag  # (!!! ì¶”ê°€ëœ ì»¬ëŸ¼ !!!)\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  > ì´ë²¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  > get_events() ì˜¤ë¥˜ (ì´ë²¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨): {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„, ë¦¬ìŠ¤íŠ¸ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜ ---\n",
    "print(\"\\n--- 8. ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ. CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ---\")\n",
    "\n",
    "if results_list:\n",
    "    df = pd.DataFrame(results_list)\n",
    "    output_filename = f\"earthquake_features_tsunami_{search_start.date}.csv\" # íŒŒì¼ ì´ë¦„ ë³€ê²½\n",
    "    output_path = os.path.join(os.getcwd(), output_filename)\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"  > ì„±ê³µ! ì´ {len(df)} ê°œì˜ ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼\")\n",
    "    print(f\"  > '{output_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"\\n[CSV ìƒ˜í”Œ ë°ì´í„°]\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"  > ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  ì´ë²¤íŠ¸ì—ì„œ íŒŒí˜• ìˆ˜ì§‘ ì‹¤íŒ¨)\")\n",
    "\n",
    "print(\"\\n--- ì‘ì—… ì¢…ë£Œ ---\")"
   ],
   "id": "cdb6aafb2bb624dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "import json\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "# --- 1. CSVì˜ ì²« ë²ˆì§¸ ì¤„ ë°ì´í„° (ê·œëª¨ 4.3) ---\n",
    "event_lat_from_iris = 37.3362\n",
    "event_lon_from_iris = 136.9617\n",
    "event_time_from_iris = UTCDateTime(\"2024-01-01T22:13:30.239000\")\n",
    "\n",
    "print(f\"--- IRISì—ì„œ ì°¾ì€ ì´ë²¤íŠ¸ ì •ë³´ (M 4.3) ---\")\n",
    "print(f\"Time: {event_time_from_iris}\")\n",
    "print(f\"Lat: {event_lat_from_iris}, Lon: {event_lon_from_iris}\\n\")\n",
    "\n",
    "# --- 2. ì´ ì´ë²¤íŠ¸ë¥¼ ìœ„í•œ 'ì‹œê³µê°„ ì°½' ì •ì˜ ---\n",
    "search_start_time = event_time_from_iris - 60  # 1ë¶„ ì „\n",
    "search_end_time = event_time_from_iris + 60    # 1ë¶„ í›„\n",
    "search_radius_km = 100 # 100km ë°˜ê²½ (ê¸°ê´€ ê°„ ìœ„ì¹˜ ì˜¤ì°¨ ê°ì•ˆ)\n",
    "\n",
    "# --- 3. USGS APIë¡œ 'ì¢ì€ ê²€ìƒ‰' ìš”ì²­ ---\n",
    "url = (\n",
    "    f\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson\"\n",
    "    f\"&starttime={search_start_time.isoformat()}\"\n",
    "    f\"&endtime={search_end_time.isoformat()}\"\n",
    "    f\"&latitude={event_lat_from_iris}\"\n",
    "    f\"&longitude={event_lon_from_iris}\"\n",
    "    f\"&maxradiuskm={search_radius_km}\"\n",
    "    # (!!!) ë°”ë¡œ ì´ ë¶€ë¶„! ìµœì†Œ ê·œëª¨ í•„í„°ë¥¼ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤ (!!!)\n",
    "    # f\"&minmagnitude=4.5\"  <- ì´ ì½”ë“œê°€ ë¬¸ì œì˜€ìŠµë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "print(f\"--- USGSì— 'ì¢ì€ ê²€ìƒ‰' ìš”ì²­ ---\")\n",
    "print(f\"URL: {url}\\n\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    num_found = len(data['features'])\n",
    "\n",
    "    if num_found == 1:\n",
    "        # --- 4. ì •í™•íˆ 1ê°œì˜ ì´ë²¤íŠ¸ë¥¼ ì°¾ì•˜ì„ ë•Œ (ì„±ê³µ!) ---\n",
    "        feature = data['features'][0]\n",
    "        props = feature['properties']\n",
    "\n",
    "        usgs_tsunami_flag = props['tsunami']\n",
    "        usgs_event_id = feature['id']\n",
    "        usgs_mag = props['mag']\n",
    "\n",
    "        print(f\"  > ì„±ê³µ! USGSì—ì„œ ë§¤ì¹­ë˜ëŠ” ì´ë²¤íŠ¸ 1ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"  > USGS ID: {usgs_event_id}\") # ì•„ë§ˆ 'us7000lsyp'ê°€ ë‚˜ì˜¬ ê²ƒì…ë‹ˆë‹¤.\n",
    "        print(f\"  > USGS Mag: {usgs_mag}\")\n",
    "        print(f\"  > *** ê³µì‹ ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ (tsunami): {usgs_tsunami_flag} ***\")\n",
    "\n",
    "        if usgs_tsunami_flag == 1:\n",
    "            print(\"  > (ê²°ê³¼: ì“°ë‚˜ë¯¸ ë°œìƒ ì´ë²¤íŠ¸)\")\n",
    "        else:\n",
    "            print(\"  > (ê²°ê³¼: ì“°ë‚˜ë¯¸ ë¯¸ë°œìƒ ì´ë²¤íŠ¸)\")\n",
    "\n",
    "    elif num_found > 1:\n",
    "        print(f\"  > ì˜¤ë¥˜: ì¢ì€ ë²”ìœ„ì—ì„œ {num_found}ê°œì˜ ì´ë²¤íŠ¸ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        # ì´ ê²½ìš°, magnitudeê°€ ê°€ì¥ ë¹„ìŠ·í•œ ê²ƒì„ ê³ ë¥´ëŠ” ë¡œì§ì´ ì¶”ê°€ë¡œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    else:\n",
    "        print(\"  > ì˜¤ë¥˜: USGS ì¹´íƒˆë¡œê·¸ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì´ë²¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  > ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ],
   "id": "d58fcdc16225303d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta # obspy ëŒ€ì‹  í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©\n",
    "\n",
    "# --- 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
    "input_filename = \"earthquake_features_2024-01-01.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(input_filename)\n",
    "    print(f\"--- '{input_filename}' íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ ì´ë²¤íŠ¸) ---\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"--- ì˜¤ë¥˜: '{input_filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ---\")\n",
    "    exit() # ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ\n",
    "\n",
    "# --- 2. USGS API ìš”ì²­ì„ ìœ„í•œ ì„¤ì • ---\n",
    "usgs_api_url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "search_radius_km = 100  # IRISì™€ USGS ê°„ì˜ ìœ„ì¹˜ ì˜¤ì°¨ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰ ë°˜ê²½\n",
    "time_window_seconds = 60 # IRISì™€ USGS ê°„ì˜ ì‹œê°„ ì˜¤ì°¨ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰ ì‹œê°„ (Â±60ì´ˆ)\n",
    "\n",
    "results_tsunami_flags = [] # USGS í”Œë˜ê·¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "print(f\"--- USGS API ì¡°íšŒë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ì´ {len(df)}ê°œ ì´ë²¤íŠ¸). ì´ë²¤íŠ¸ë‹¹ ì•½ 1ì´ˆê°€ ì†Œìš”ë©ë‹ˆë‹¤. ---\")\n",
    "\n",
    "# --- 3. DataFrameì˜ 'ëª¨ë“  í–‰'ì„ ìˆœíšŒ ---\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # CSVì—ì„œ í˜„ì¬ ì´ë²¤íŠ¸ ì •ë³´ ì¶”ì¶œ\n",
    "    event_lat = row['latitude']\n",
    "    event_lon = row['longitude']\n",
    "    event_mag = row['magnitude']\n",
    "    event_time_str = row['time_utc'] # ë¬¸ìì—´ë¡œ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "    try:\n",
    "        # CSVì˜ ì‹œê°„ í˜•ì‹: '2024-01-01T22:27:01.373000'\n",
    "        event_time_dt = datetime.strptime(event_time_str, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    except ValueError:\n",
    "        # ê°€ë” ë§ˆì´í¬ë¡œì´ˆ(.f)ê°€ ì—†ëŠ” ì‹œê°„ í˜•ì‹ì„ ëŒ€ë¹„\n",
    "        try:\n",
    "            event_time_dt = datetime.strptime(event_time_str, '%Y-%m-%dT%H:%M:%S')\n",
    "        except Exception as e:\n",
    "            print(f\"  > ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜ (í–‰ {index}): {e}. ì´ í–‰ì€ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            results_tsunami_flags.append(np.nan)\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n--- [ {index + 1} / {len(df)} ] ì²˜ë¦¬ ì¤‘ (IRIS Mag: {event_mag}) ---\")\n",
    "    print(f\"  > IRIS ì‹œê°„: {event_time_dt.isoformat()}\")\n",
    "\n",
    "    # USGS ê²€ìƒ‰ì„ ìœ„í•œ 'ì‹œê³µê°„ ì°½' ì„¤ì • (timedelta ì‚¬ìš©)\n",
    "    search_start_dt = event_time_dt - timedelta(seconds=time_window_seconds)\n",
    "    search_end_dt = event_time_dt + timedelta(seconds=time_window_seconds)\n",
    "\n",
    "    # APIê°€ ìš”êµ¬í•˜ëŠ” ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (UTC í‘œê¸° 'Z' ì¶”ê°€)\n",
    "    search_start_iso = search_start_dt.isoformat() + \"Z\"\n",
    "    search_end_iso = search_end_dt.isoformat() + \"Z\"\n",
    "\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° (!!! minmagnitude í•„í„° ì œê±° !!!)\n",
    "    params = {\n",
    "        'format': 'geojson',\n",
    "        'starttime': search_start_iso,\n",
    "        'endtime': search_end_iso,\n",
    "        'latitude': event_lat,\n",
    "        'longitude': event_lon,\n",
    "        'maxradiuskm': search_radius_km\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # --- 4. USGS API í˜¸ì¶œ ---\n",
    "        response = requests.get(usgs_api_url, params=params, timeout=10)\n",
    "\n",
    "        usgs_tsunami_flag = np.nan # ê¸°ë³¸ê°’ì€ 'ë°ì´í„° ì—†ìŒ'\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "\n",
    "            # --- 5. API ì‘ë‹µ ê²°ê³¼ ì²˜ë¦¬ ---\n",
    "            if len(features) == 0:\n",
    "                # Case 1: ì¢ì€ ë²”ìœ„ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì´ë²¤íŠ¸ 'ì—†ìŒ'\n",
    "                print(\"  > USGS ë§¤ì¹­ ì‹¤íŒ¨ (0ê°œ). ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ '0'ìœ¼ë¡œ ì„¤ì •.\")\n",
    "                usgs_tsunami_flag = 0 # ë§¤ì¹­ì´ ì•ˆë˜ë©´ ì“°ë‚˜ë¯¸ê°€ ì•„ë‹ˆë¼ê³  ê°€ì •\n",
    "\n",
    "            elif len(features) == 1:\n",
    "                # Case 2: 1ê°œë¡œ 'ì •í™•íˆ' ë§¤ì¹­ë¨ (Best case)\n",
    "                props = features[0]['properties']\n",
    "                usgs_tsunami_flag = props['tsunami']\n",
    "                print(f\"  > USGS ë§¤ì¹­ ì„±ê³µ (1ê°œ)! (ID: {features[0]['id']}, Mag: {props['mag']})\")\n",
    "                print(f\"  > *** ê³µì‹ ì“°ë‚˜ë¯¸ í”Œë˜ê·¸: {usgs_tsunami_flag} ***\")\n",
    "\n",
    "            else:\n",
    "                # Case 3: 2ê°œ ì´ìƒ 'ëª¨í˜¸í•˜ê²Œ' ë§¤ì¹­ë¨\n",
    "                print(f\"  > USGS ë§¤ì¹­ ëª¨í˜¸í•¨ ({len(features)}ê°œ ë°œê²¬). ê·œëª¨ê°€ ê°€ì¥ ë¹„ìŠ·í•œ ì´ë²¤íŠ¸ë¡œ ë§¤ì¹­ ì‹œë„...\")\n",
    "\n",
    "                best_match = None\n",
    "                min_mag_diff = float('inf')\n",
    "\n",
    "                # IRISì˜ ê·œëª¨(event_mag)ì™€ ê°€ì¥ ì°¨ì´ê°€ ì ê²Œ ë‚˜ëŠ” ì´ë²¤íŠ¸ë¥¼ ì°¾ëŠ”ë‹¤\n",
    "                for f in features:\n",
    "                    usgs_mag = f['properties']['mag']\n",
    "                    if usgs_mag is None: continue\n",
    "\n",
    "                    mag_diff = abs(usgs_mag - event_mag)\n",
    "\n",
    "                    if mag_diff < min_mag_diff:\n",
    "                        min_mag_diff = mag_diff\n",
    "                        best_match = f\n",
    "\n",
    "                if best_match:\n",
    "                    props = best_match['properties']\n",
    "                    usgs_tsunami_flag = props['tsunami']\n",
    "                    print(f\"  > > ìµœì  ë§¤ì¹­: (ID: {best_match['id']}, Mag: {props['mag']})\")\n",
    "                    print(f\"  > *** ê³µì‹ ì“°ë‚˜ë¯¸ í”Œë˜ê·¸: {usgs_tsunami_flag} ***\")\n",
    "                else:\n",
    "                    print(\"  > > ìµœì  ë§¤ì¹­ ì‹¤íŒ¨. í”Œë˜ê·¸ '0'ìœ¼ë¡œ ì„¤ì •.\")\n",
    "                    usgs_tsunami_flag = 0 # ê·¸ë˜ë„ ëª»ì°¾ìœ¼ë©´ 0\n",
    "\n",
    "        else:\n",
    "            # API ìì²´ê°€ ì‹¤íŒ¨í•œ ê²½ìš° (e.g., 500 ì„œë²„ ì˜¤ë¥˜)\n",
    "            print(f\"  > USGS API ìš”ì²­ ì‹¤íŒ¨ (HTTP Status: {response.status_code}).\")\n",
    "            usgs_tsunami_flag = np.nan # '0'ì´ ì•„ë‹ˆë¼ 'ë°ì´í„° ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        # ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ ë“±\n",
    "        print(f\"  > API ìš”ì²­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}\")\n",
    "        usgs_tsunami_flag = np.nan # 'ë°ì´í„° ì—†ìŒ'\n",
    "\n",
    "    # ìµœì¢… í”Œë˜ê·¸ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    results_tsunami_flags.append(usgs_tsunami_flag)\n",
    "\n",
    "    # !!! USGS API ì„œë²„ ê³¼ë¶€í•˜ë¥¼ ë§‰ê¸° ìœ„í•´ 1ì´ˆ ëŒ€ê¸° (ë§¤ìš° ì¤‘ìš”) !!!\n",
    "    time.sleep(1)\n",
    "\n",
    "# --- 6. ì›ë³¸ DataFrameì— ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€ ---\n",
    "df['tsunami_flag_usgs'] = results_tsunami_flags\n",
    "\n",
    "# --- 7. ìƒˆ íŒŒì¼ë¡œ ì €ì¥ ---\n",
    "output_filename = f\"earthquake_features_with_tsunami_usgs.csv\"\n",
    "output_path = os.path.join(os.getcwd(), output_filename)\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n--- ì‘ì—… ì™„ë£Œ ---\")\n",
    "print(f\"  > '{output_path}' íŒŒì¼ì— USGS ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ê°€ ì¶”ê°€ëœ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"\\n[ìµœì¢… ë°ì´í„° ìƒ˜í”Œ (tsunami_flag_usgs ì»¬ëŸ¼ í™•ì¸)]\")\n",
    "print(df.head())\n",
    "\n",
    "# ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ê°€ 1ì¸ (ì¦‰, ì“°ë‚˜ë¯¸ê°€ ë°œìƒí•œ) ì´ë²¤íŠ¸ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸\n",
    "tsunami_events = df[df['tsunami_flag_usgs'] == 1]\n",
    "if not tsunami_events.empty:\n",
    "    print(\"\\n[!!! ì“°ë‚˜ë¯¸(1)ë¡œ í™•ì¸ëœ ì´ë²¤íŠ¸ !!!]\")\n",
    "    print(tsunami_events[['time_utc', 'magnitude', 'tsunami_flag_usgs']])\n",
    "else:\n",
    "    print(\"\\n[í™•ì¸: ì´ ë°ì´í„°ì…‹ì—ì„œ ì“°ë‚˜ë¯¸(1)ë¡œ í™•ì¸ëœ ì´ë²¤íŠ¸ëŠ” ì—†ìŠµë‹ˆë‹¤.]\")"
   ],
   "id": "8bb5757efd7b92bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T13:17:48.054875500Z",
     "start_time": "2025-11-05T13:17:45.325424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta # obspy ëŒ€ì‹  í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©\n",
    "\n",
    "# --- 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
    "input_filename = \"earthquake_features_2024-12-01.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(input_filename)\n",
    "    print(f\"--- '{input_filename}' íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ ì´ë²¤íŠ¸) ---\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"--- ì˜¤ë¥˜: '{input_filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ---\")\n",
    "    exit() # ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ\n",
    "\n",
    "# --- 2. USGS API ìš”ì²­ì„ ìœ„í•œ ì„¤ì • ---\n",
    "usgs_api_url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "search_radius_km = 100  # IRISì™€ USGS ê°„ì˜ ìœ„ì¹˜ ì˜¤ì°¨ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰ ë°˜ê²½\n",
    "time_window_seconds = 60 # IRISì™€ USGS ê°„ì˜ ì‹œê°„ ì˜¤ì°¨ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰ ì‹œê°„ (Â±60ì´ˆ)\n",
    "\n",
    "results_tsunami_flags = [] # USGS í”Œë˜ê·¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "print(f\"--- USGS API ì¡°íšŒë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ì´ {len(df)}ê°œ ì´ë²¤íŠ¸). ì´ë²¤íŠ¸ë‹¹ ì•½ 1ì´ˆê°€ ì†Œìš”ë©ë‹ˆë‹¤. ---\")\n",
    "\n",
    "# --- 3. DataFrameì˜ 'ëª¨ë“  í–‰'ì„ ìˆœíšŒ ---\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # CSVì—ì„œ í˜„ì¬ ì´ë²¤íŠ¸ ì •ë³´ ì¶”ì¶œ\n",
    "    event_lat = row['latitude']\n",
    "    event_lon = row['longitude']\n",
    "    event_mag = row['magnitude']\n",
    "    event_time_str = row['time_utc'] # ë¬¸ìì—´ë¡œ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "    try:\n",
    "        # CSVì˜ ì‹œê°„ í˜•ì‹: '2024-01-01T22:27:01.373000'\n",
    "        event_time_dt = datetime.strptime(event_time_str, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    except ValueError:\n",
    "        # ê°€ë” ë§ˆì´í¬ë¡œì´ˆ(.f)ê°€ ì—†ëŠ” ì‹œê°„ í˜•ì‹ì„ ëŒ€ë¹„\n",
    "        try:\n",
    "            event_time_dt = datetime.strptime(event_time_str, '%Y-%m-%dT%H:%M:%S')\n",
    "        except Exception as e:\n",
    "            print(f\"  > ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜ (í–‰ {index}): {e}. ì´ í–‰ì€ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            results_tsunami_flags.append(np.nan)\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n--- [ {index + 1} / {len(df)} ] ì²˜ë¦¬ ì¤‘ (IRIS Mag: {event_mag}) ---\")\n",
    "    print(f\"  > IRIS ì‹œê°„: {event_time_dt.isoformat()}\")\n",
    "\n",
    "    # USGS ê²€ìƒ‰ì„ ìœ„í•œ 'ì‹œê³µê°„ ì°½' ì„¤ì • (timedelta ì‚¬ìš©)\n",
    "    search_start_dt = event_time_dt - timedelta(seconds=time_window_seconds)\n",
    "    search_end_dt = event_time_dt + timedelta(seconds=time_window_seconds)\n",
    "\n",
    "    # APIê°€ ìš”êµ¬í•˜ëŠ” ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (UTC í‘œê¸° 'Z' ì¶”ê°€)\n",
    "    search_start_iso = search_start_dt.isoformat() + \"Z\"\n",
    "    search_end_iso = search_end_dt.isoformat() + \"Z\"\n",
    "\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° (!!! minmagnitude í•„í„° ì œê±° !!!)\n",
    "    params = {\n",
    "        'format': 'geojson',\n",
    "        'starttime': search_start_iso,\n",
    "        'endtime': search_end_iso,\n",
    "        'latitude': event_lat,\n",
    "        'longitude': event_lon,\n",
    "        'maxradiuskm': search_radius_km\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # --- 4. USGS API í˜¸ì¶œ ---\n",
    "        response = requests.get(usgs_api_url, params=params, timeout=10)\n",
    "\n",
    "        usgs_tsunami_flag = np.nan # ê¸°ë³¸ê°’ì€ 'ë°ì´í„° ì—†ìŒ'\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "\n",
    "            # --- 5. API ì‘ë‹µ ê²°ê³¼ ì²˜ë¦¬ ---\n",
    "            if len(features) == 0:\n",
    "                # Case 1: ì¢ì€ ë²”ìœ„ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì´ë²¤íŠ¸ 'ì—†ìŒ'\n",
    "                print(\"  > USGS ë§¤ì¹­ ì‹¤íŒ¨ (0ê°œ). ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ '0'ìœ¼ë¡œ ì„¤ì •.\")\n",
    "                usgs_tsunami_flag = 0 # ë§¤ì¹­ì´ ì•ˆë˜ë©´ ì“°ë‚˜ë¯¸ê°€ ì•„ë‹ˆë¼ê³  ê°€ì •\n",
    "\n",
    "            elif len(features) == 1:\n",
    "                # Case 2: 1ê°œë¡œ 'ì •í™•íˆ' ë§¤ì¹­ë¨ (Best case)\n",
    "                props = features[0]['properties']\n",
    "                usgs_tsunami_flag = props['tsunami']\n",
    "                print(f\"  > USGS ë§¤ì¹­ ì„±ê³µ (1ê°œ)! (ID: {features[0]['id']}, Mag: {props['mag']})\")\n",
    "                print(f\"  > *** ê³µì‹ ì“°ë‚˜ë¯¸ í”Œë˜ê·¸: {usgs_tsunami_flag} ***\")\n",
    "\n",
    "            else:\n",
    "                # Case 3: 2ê°œ ì´ìƒ 'ëª¨í˜¸í•˜ê²Œ' ë§¤ì¹­ë¨\n",
    "                print(f\"  > USGS ë§¤ì¹­ ëª¨í˜¸í•¨ ({len(features)}ê°œ ë°œê²¬). ê·œëª¨ê°€ ê°€ì¥ ë¹„ìŠ·í•œ ì´ë²¤íŠ¸ë¡œ ë§¤ì¹­ ì‹œë„...\")\n",
    "\n",
    "                best_match = None\n",
    "                min_mag_diff = float('inf')\n",
    "\n",
    "                # IRISì˜ ê·œëª¨(event_mag)ì™€ ê°€ì¥ ì°¨ì´ê°€ ì ê²Œ ë‚˜ëŠ” ì´ë²¤íŠ¸ë¥¼ ì°¾ëŠ”ë‹¤\n",
    "                for f in features:\n",
    "                    usgs_mag = f['properties']['mag']\n",
    "                    if usgs_mag is None: continue\n",
    "\n",
    "                    mag_diff = abs(usgs_mag - event_mag)\n",
    "\n",
    "                    if mag_diff < min_mag_diff:\n",
    "                        min_mag_diff = mag_diff\n",
    "                        best_match = f\n",
    "\n",
    "                if best_match:\n",
    "                    props = best_match['properties']\n",
    "                    usgs_tsunami_flag = props['tsunami']\n",
    "                    print(f\"  > > ìµœì  ë§¤ì¹­: (ID: {best_match['id']}, Mag: {props['mag']})\")\n",
    "                    print(f\"  > *** ê³µì‹ ì“°ë‚˜ë¯¸ í”Œë˜ê·¸: {usgs_tsunami_flag} ***\")\n",
    "                else:\n",
    "                    print(\"  > > ìµœì  ë§¤ì¹­ ì‹¤íŒ¨. í”Œë˜ê·¸ '0'ìœ¼ë¡œ ì„¤ì •.\")\n",
    "                    usgs_tsunami_flag = 0 # ê·¸ë˜ë„ ëª»ì°¾ìœ¼ë©´ 0\n",
    "\n",
    "        else:\n",
    "            # API ìì²´ê°€ ì‹¤íŒ¨í•œ ê²½ìš° (e.g., 500 ì„œë²„ ì˜¤ë¥˜)\n",
    "            print(f\"  > USGS API ìš”ì²­ ì‹¤íŒ¨ (HTTP Status: {response.status_code}).\")\n",
    "            usgs_tsunami_flag = np.nan # '0'ì´ ì•„ë‹ˆë¼ 'ë°ì´í„° ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        # ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ ë“±\n",
    "        print(f\"  > API ìš”ì²­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}\")\n",
    "        usgs_tsunami_flag = np.nan # 'ë°ì´í„° ì—†ìŒ'\n",
    "\n",
    "    # ìµœì¢… í”Œë˜ê·¸ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    results_tsunami_flags.append(usgs_tsunami_flag)\n",
    "\n",
    "    # !!! USGS API ì„œë²„ ê³¼ë¶€í•˜ë¥¼ ë§‰ê¸° ìœ„í•´ 1ì´ˆ ëŒ€ê¸° (ë§¤ìš° ì¤‘ìš”) !!!\n",
    "    time.sleep(1)\n",
    "\n",
    "# --- 6. ì›ë³¸ DataFrameì— ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€ ---\n",
    "df['tsunami_flag_usgs'] = results_tsunami_flags\n",
    "\n",
    "# --- 7. ìƒˆ íŒŒì¼ë¡œ ì €ì¥ ---\n",
    "output_filename = f\"earthquake_features_2024-12-01_Tsunami.csv\"\n",
    "output_path = os.path.join(os.getcwd(), output_filename)\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n--- ì‘ì—… ì™„ë£Œ ---\")\n",
    "print(f\"  > '{output_path}' íŒŒì¼ì— USGS ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ê°€ ì¶”ê°€ëœ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"\\n[ìµœì¢… ë°ì´í„° ìƒ˜í”Œ (tsunami_flag_usgs ì»¬ëŸ¼ í™•ì¸)]\")\n",
    "print(df.head())\n",
    "\n",
    "# ì“°ë‚˜ë¯¸ í”Œë˜ê·¸ê°€ 1ì¸ (ì¦‰, ì“°ë‚˜ë¯¸ê°€ ë°œìƒí•œ) ì´ë²¤íŠ¸ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸\n",
    "tsunami_events = df[df['tsunami_flag_usgs'] == 1]\n",
    "if not tsunami_events.empty:\n",
    "    print(\"\\n[!!! ì“°ë‚˜ë¯¸(1)ë¡œ í™•ì¸ëœ ì´ë²¤íŠ¸ !!!]\")\n",
    "    print(tsunami_events[['time_utc', 'magnitude', 'tsunami_flag_usgs']])\n",
    "else:\n",
    "    print(\"\\n[í™•ì¸: ì´ ë°ì´í„°ì…‹ì—ì„œ ì“°ë‚˜ë¯¸(1)ë¡œ í™•ì¸ëœ ì´ë²¤íŠ¸ëŠ” ì—†ìŠµë‹ˆë‹¤.]\")"
   ],
   "id": "629d1bc114ef7b7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'earthquake_features_2024-12-01.csv' íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì´ 803ê°œ ì´ë²¤íŠ¸) ---\n",
      "--- USGS API ì¡°íšŒë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ì´ 803ê°œ ì´ë²¤íŠ¸). ì´ë²¤íŠ¸ë‹¹ ì•½ 1ì´ˆê°€ ì†Œìš”ë©ë‹ˆë‹¤. ---\n",
      "\n",
      "--- [ 1 / 803 ] ì²˜ë¦¬ ì¤‘ (IRIS Mag: 4.3) ---\n",
      "  > IRIS ì‹œê°„: 2024-12-31T23:28:55.746000\n",
      "  > USGS ë§¤ì¹­ ì„±ê³µ (1ê°œ)! (ID: us6000pj8c, Mag: 4.3)\n",
      "  > *** ê³µì‹ ì“°ë‚˜ë¯¸ í”Œë˜ê·¸: 0 ***\n",
      "\n",
      "--- [ 2 / 803 ] ì²˜ë¦¬ ì¤‘ (IRIS Mag: 5.0) ---\n",
      "  > IRIS ì‹œê°„: 2024-12-31T23:13:20.048000\n",
      "  > USGS ë§¤ì¹­ ì„±ê³µ (1ê°œ)! (ID: us6000pgri, Mag: 5)\n",
      "  > *** ê³µì‹ ì“°ë‚˜ë¯¸ í”Œë˜ê·¸: 0 ***\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T13:27:05.270721Z",
     "start_time": "2025-11-05T13:27:00.590442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import great_circle\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. ì„¤ì • ---\n",
    "RADIUS_KM = 60.0\n",
    "\n",
    "# --- 2. 12ê°œ íŒŒì¼ ì°¾ê¸° ---\n",
    "file_pattern = \"earthquake_features_*_Tsunami.csv\"\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "if not csv_files:\n",
    "    print(f\"ì˜¤ë¥˜: '{file_pattern}' íŒ¨í„´ì˜ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"ì´ {len(csv_files)}ê°œì˜ '..._Tsunami.csv' íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. 'ì—¬ì§„ ì œê±°'ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# --- 3. ë©”ì¸ 'ì—¬ì§„ ì œê±°(Declustering)' ë£¨í”„ ---\n",
    "\n",
    "# 3-1. 12ê°œ íŒŒì¼ ìˆœíšŒ\n",
    "for file_path in tqdm(csv_files, desc=\"ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ \"):\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"'{file_path}' íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
    "        continue\n",
    "\n",
    "    # (ì¤‘ìš”) ë‚ ì§œ/ì‹œê°„(time_utc) ì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜\n",
    "    try:\n",
    "        # â˜…â˜…â˜… (ìˆ˜ì •ë¨) â˜…â˜…â˜…\n",
    "        # format='mixed' ëŒ€ì‹  errors='coerce' ì‚¬ìš©.\n",
    "        # ë³€í™˜ì´ ë¶ˆê°€ëŠ¥í•œ 'ê¹¨ì§„' ë‚ ì§œëŠ” NaT(Not a Time)ë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n",
    "        df['time_utc'] = pd.to_datetime(df['time_utc'], errors='coerce')\n",
    "\n",
    "        # (ì¶”ê°€) NaTë¡œ ë°”ë€, ì¦‰ 'ê¹¨ì§„' í–‰ì€ ëª¨ë‘ ì‚­ì œ\n",
    "        original_rows_before_coerce = len(df)\n",
    "        df = df.dropna(subset=['time_utc'])\n",
    "        cleaned_rows_after_coerce = len(df)\n",
    "\n",
    "        if original_rows_before_coerce != cleaned_rows_after_coerce:\n",
    "            print(f\"\\n[{os.path.basename(file_path)}] 'ê¹¨ì§„' ë‚ ì§œ ë°ì´í„° {original_rows_before_coerce - cleaned_rows_after_coerce}í–‰ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"\\nì˜¤ë¥˜: '{file_path}'ì— 'time_utc' ì—´ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "        continue\n",
    "\n",
    "    df['day'] = df['time_utc'].dt.day\n",
    "\n",
    "    indices_to_keep = set()\n",
    "    processed_indices = set()\n",
    "    original_row_count = len(df) # ê¹¨ë—í•œ í–‰ ê¸°ì¤€\n",
    "\n",
    "    # 3-2. ë‚ ì§œ(day)ë³„ë¡œ ìˆœíšŒ\n",
    "    for day in df['day'].unique():\n",
    "\n",
    "        day_df_indices = df[df['day'] == day].index\n",
    "\n",
    "        # 3-3. ë‚ ì§œë³„ $O(n^2)$ ê±°ë¦¬ ë¹„êµ\n",
    "        for i in day_df_indices:\n",
    "\n",
    "            if i in processed_indices:\n",
    "                continue\n",
    "\n",
    "            current_quake = df.loc[i]\n",
    "            current_coords = (current_quake['latitude'], current_quake['longitude'])\n",
    "\n",
    "            cluster_indices = [i]\n",
    "\n",
    "            for j in day_df_indices:\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                compare_quake = df.loc[j]\n",
    "                compare_coords = (compare_quake['latitude'], compare_quake['longitude'])\n",
    "\n",
    "                dist = great_circle(current_coords, compare_coords).km\n",
    "\n",
    "                if dist <= RADIUS_KM:\n",
    "                    cluster_indices.append(j)\n",
    "\n",
    "            # 3-4. í´ëŸ¬ìŠ¤í„° ì²˜ë¦¬\n",
    "            processed_indices.update(cluster_indices)\n",
    "            mainshock_index = df.loc[cluster_indices]['magnitude'].idxmax()\n",
    "            indices_to_keep.add(mainshock_index)\n",
    "\n",
    "    # 3-5. (ë®ì–´ì“°ê¸°) ì‚´ì•„ë‚¨ì€ ë³¸ì§„ë“¤ë§Œ í•„í„°ë§\n",
    "    df_cleaned = df.loc[list(indices_to_keep)]\n",
    "    df_cleaned = df_cleaned.drop(columns=['day'])\n",
    "\n",
    "    # 3-6. (ë®ì–´ì“°ê¸°) ì›ë³¸ íŒŒì¼ ê²½ë¡œì— ê·¸ëŒ€ë¡œ ì €ì¥\n",
    "    try:\n",
    "        df_cleaned.to_csv(file_path, index=False)\n",
    "        print(f\"\\n[ì„±ê³µ] '{os.path.basename(file_path)}' ë®ì–´ì“°ê¸° ì™„ë£Œ.\")\n",
    "        print(f\"  -> ì›ë³¸(ì •ë¦¬ í›„): {original_row_count} í–‰ => 'ë³¸ì§„'ë§Œ: {len(df_cleaned)} í–‰\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ì‹¤íŒ¨] '{os.path.basename(file_path)}' ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ ëª¨ë“  íŒŒì¼ì˜ 'ì—¬ì§„ ì œê±°' ë° 'ë®ì–´ì“°ê¸°'ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ],
   "id": "6452e8069b389f11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 12ê°œì˜ '..._Tsunami.csv' íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. 'ì—¬ì§„ ì œê±°'ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :   8%|â–Š         | 1/12 [00:00<00:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-01-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 533 í–‰ => 'ë³¸ì§„'ë§Œ: 532 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  17%|â–ˆâ–‹        | 2/12 [00:01<00:05,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-02-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 592 í–‰ => 'ë³¸ì§„'ë§Œ: 591 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:01<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-03-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 500 í–‰ => 'ë³¸ì§„'ë§Œ: 500 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:01<00:03,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-04-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 510 í–‰ => 'ë³¸ì§„'ë§Œ: 508 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:02<00:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-05-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 485 í–‰ => 'ë³¸ì§„'ë§Œ: 484 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:02<00:02,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-06-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 461 í–‰ => 'ë³¸ì§„'ë§Œ: 461 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:02<00:01,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-07-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 422 í–‰ => 'ë³¸ì§„'ë§Œ: 422 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:03<00:01,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-08-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 408 í–‰ => 'ë³¸ì§„'ë§Œ: 408 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:03<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-09-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 410 í–‰ => 'ë³¸ì§„'ë§Œ: 410 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:03<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-10-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 521 í–‰ => 'ë³¸ì§„'ë§Œ: 521 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ :  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:04<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-11-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 482 í–‰ => 'ë³¸ì§„'ë§Œ: 482 í–‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:04<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„±ê³µ] 'earthquake_features_2024-12-01_Tsunami.csv' ë®ì–´ì“°ê¸° ì™„ë£Œ.\n",
      "  -> ì›ë³¸(ì •ë¦¬ í›„): 555 í–‰ => 'ë³¸ì§„'ë§Œ: 553 í–‰\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ ëª¨ë“  íŒŒì¼ì˜ 'ì—¬ì§„ ì œê±°' ë° 'ë®ì–´ì“°ê¸°'ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
